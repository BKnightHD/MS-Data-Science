{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "45afe8e1386bb813621db67c1e85d2c1",
     "grade": false,
     "grade_id": "cell-8a70a56233894d42",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Homework 2\n",
    "***\n",
    "**Name**: $<$insert name here$>$ \n",
    "***\n",
    "\n",
    "Remember that you are encouraged to discuss the problems with your instructors and classmates, but **you must write all code and solutions on your own**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1b98fbdff894309fe3937b7d4d55eb34",
     "grade": false,
     "grade_id": "cell-d3925f1a2ed0ba39",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The rules to be followed for the assignment are:\n",
    "\n",
    "- Do **NOT** load additional packages beyond what we've shared in the cells below. \n",
    "- Some problems with code may be autograded.  If we provide a function or class API **do not** change it.\n",
    "- Do not change the location of the data or data directory.  Use only relative paths to access the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T01:22:03.370195Z",
     "start_time": "2020-09-10T01:22:02.356211Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "728bb8c12435a7d8af07857e799b9025",
     "grade": false,
     "grade_id": "cell-76950cd59a275b9b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3c78a88f5de1e17ba4a6a9bc1ce64784",
     "grade": false,
     "grade_id": "cell-eeb3bd05ca5a2672",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Problem 1\n",
    "***\n",
    "\n",
    "There are two functions that need to be completed:\n",
    "\n",
    "#### normalization(fname, attr, normType)\n",
    "\n",
    "- This function takes in the location of the data file, the attribute that has to be normalised (one of the values from 'Open','High','Low','Close','Volume', given as column indices) and the type of normalization to be performed ('min_max' or 'z_score')\n",
    "\n",
    "- Based on the normalisation type that is mentioned, you will have to apply the appropriate formula and return a dictionary where key = original value in the dataset, value = normalised value\n",
    "\n",
    "- A sample dataset has been provided to you at this location \"./data/HistoricalQuotes.csv\". Use this dataset to test the functionality you are building.\n",
    "\n",
    "#### correlation (fname1, attr1, fname2, attr2)\n",
    "\n",
    "- This function takes in the location of the first data file, the attribute that has to be used in the first file, the location of the second data file and the attribute that has to be used in the second file.\n",
    "\n",
    "- This function has to calculate the correlation coefficient between the two attributes mentioned in the two files.\n",
    "\n",
    "- Two Sample datasets have been provided to you in \"./data/test1.csv\" and \"./data/test2.csv\" respectively.\n",
    "\n",
    "- The two sample files have the following attributes 'Open','High','Last','Low','Volume'. Use these two sample files to test the functionality you are building.\n",
    "\n",
    "Note:\n",
    "- If the test case fails, one way to debug is to see the output of the testing data and comparing it to your output.\n",
    "- Initially the test case will be failed as there is no code in the below two functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T01:24:33.428213Z",
     "start_time": "2020-09-10T01:24:33.423898Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5bc7e76c2c1a5ce1942a310ff8c6ce8f",
     "grade": false,
     "grade_id": "normalization",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{38.1: 0.7637474541751528,\n",
       " 38.4301: 0.77409055303149,\n",
       " 40.96: 0.8533604887983707,\n",
       " 41.36: 0.8658937803540655,\n",
       " 40.14: 0.8276672411091963,\n",
       " 40.565: 0.8409838633871219,\n",
       " 40.42: 0.8364405451981827,\n",
       " 40.07: 0.8254739150869497,\n",
       " 40.0: 0.8232805890647031,\n",
       " 39.32: 0.801973993420022,\n",
       " 39.64: 0.8120006266645777,\n",
       " 38.7: 0.782547391508695,\n",
       " 38.3: 0.7700140999530001,\n",
       " 38.06: 0.7624941250195834,\n",
       " 37.74: 0.7524674917750275,\n",
       " 37.27: 0.7377408741970861,\n",
       " 37.28: 0.7380542064859784,\n",
       " 37.37: 0.7408741970860097,\n",
       " 36.8207: 0.7236628544571518,\n",
       " 36.71: 0.7201942660191133,\n",
       " 37.31: 0.7389942033526555,\n",
       " 36.73: 0.7208209305968979,\n",
       " 36.49: 0.7133009556634812,\n",
       " 36.41: 0.710794297352342,\n",
       " 35.65: 0.686981043396522,\n",
       " 35.9038: 0.6949334168886102,\n",
       " 35.97: 0.6970076766410778,\n",
       " 36.38: 0.7098543004856651,\n",
       " 36.09: 0.7007676641077863,\n",
       " 37.14: 0.7336675544414852,\n",
       " 37.5: 0.7449475168416105,\n",
       " 36.25: 0.7057809807300642,\n",
       " 37.0: 0.729280902396992,\n",
       " 35.8: 0.6916810277299075,\n",
       " 34.73: 0.6581544728184238,\n",
       " 34.0: 0.6352812157292809,\n",
       " 34.6207: 0.6547297509008303,\n",
       " 33.44: 0.617734607551308,\n",
       " 33.76: 0.6277612407958639,\n",
       " 34.86: 0.6622277925740248,\n",
       " 34.81: 0.6606611311295629,\n",
       " 32.73: 0.5954880150399497,\n",
       " 31.765: 0.5652514491618361,\n",
       " 31.155: 0.5461381795394016,\n",
       " 30.395: 0.5223249255835815,\n",
       " 30.06: 0.5118282939056871,\n",
       " 29.02: 0.4792417358608805,\n",
       " 28.23: 0.45448848503838324,\n",
       " 28.75: 0.4707817640607865,\n",
       " 30.82: 0.5356415478615071,\n",
       " 31.34: 0.5519348268839105,\n",
       " 32.7301: 0.5954911483628388,\n",
       " 32.95: 0.6023813253955821,\n",
       " 33.4: 0.6164812783957386,\n",
       " 33.86: 0.6308945636847877,\n",
       " 34.1: 0.6384145386182046,\n",
       " 34.21: 0.6418611937960207,\n",
       " 32.84: 0.598934670217766,\n",
       " 32.47: 0.5873413755287482,\n",
       " 32.72: 0.5951746827510574,\n",
       " 34.9: 0.6634811217295942,\n",
       " 35.163000000000004: 0.6717217609274637,\n",
       " 35.75: 0.6901143662854456,\n",
       " 34.47: 0.6500078333072222,\n",
       " 33.34: 0.6146012846623845,\n",
       " 32.44: 0.586401378662071,\n",
       " 31.61: 0.5603947986840043,\n",
       " 30.84: 0.5362682124392919,\n",
       " 30.29: 0.5190349365502115,\n",
       " 31.32: 0.5513081623061257,\n",
       " 32.235: 0.5799780667397775,\n",
       " 33.36: 0.6152279492401691,\n",
       " 31.775: 0.5655647814507284,\n",
       " 31.39: 0.5535014883283722,\n",
       " 30.45: 0.5240482531724895,\n",
       " 29.325: 0.48879837067209775,\n",
       " 29.56: 0.49616167946106843,\n",
       " 28.11: 0.45072849757167477,\n",
       " 27.12: 0.41970860097133017,\n",
       " 27.58: 0.4341218862603791,\n",
       " 29.09: 0.48143506188312707,\n",
       " 29.3318: 0.4890114366285446,\n",
       " 28.74: 0.47046843177189407,\n",
       " 27.94: 0.44540184866050453,\n",
       " 27.553: 0.4332758890803698,\n",
       " 27.9: 0.44414851950493495,\n",
       " 27.39: 0.4281685727714241,\n",
       " 27.1915: 0.4219489268369106,\n",
       " 28.085: 0.4499451668494439,\n",
       " 29.62: 0.4980416731944227,\n",
       " 28.5734: 0.4652483158389472,\n",
       " 29.13: 0.48268839103869654,\n",
       " 27.46: 0.43036189879367076,\n",
       " 27.73: 0.4388218705937647,\n",
       " 26.45: 0.3987153376155413,\n",
       " 25.055: 0.3550054833150556,\n",
       " 26.11: 0.3880620397932007,\n",
       " 26.47: 0.399342002193326,\n",
       " 25.955: 0.3832053893153689,\n",
       " 26.75: 0.4081153062823124,\n",
       " 27.6: 0.43474855083816394,\n",
       " 26.24: 0.39213535954880147,\n",
       " 27.28: 0.42472191759360806,\n",
       " 25.92: 0.38210872630424575,\n",
       " 25.3102: 0.3630017233275889,\n",
       " 23.79: 0.31536894877017074,\n",
       " 22.75: 0.28278239072536426,\n",
       " 22.36: 0.2705624314585618,\n",
       " 23.05: 0.2921823593921354,\n",
       " 24.4: 0.33448221839260533,\n",
       " 24.6: 0.3407488641704528,\n",
       " 24.76: 0.34576218079273074,\n",
       " 25.625: 0.3728654237819207,\n",
       " 24.52: 0.3382422058593138,\n",
       " 24.13: 0.32602224659251133,\n",
       " 23.5: 0.30628231239229203,\n",
       " 23.7: 0.31254895817013945,\n",
       " 20.6558: 0.21716434278552404,\n",
       " 20.0: 0.19661601127996242,\n",
       " 23.18: 0.2962556791477362,\n",
       " 23.92: 0.3194422685257717,\n",
       " 26.4001: 0.39715180949396833,\n",
       " 26.7: 0.4065486448378505,\n",
       " 30.01: 0.5102616324612252,\n",
       " 33.12: 0.6077079743067522,\n",
       " 30.62: 0.5293749020836598,\n",
       " 32.51: 0.5885947046843176,\n",
       " 34.52: 0.6515744947516843,\n",
       " 34.77: 0.6594078019739935,\n",
       " 34.41: 0.648127839573868,\n",
       " 35.14: 0.6710010966630111,\n",
       " 31.51: 0.5572614757950808,\n",
       " 34.435: 0.648911170296099,\n",
       " 34.885: 0.6630111232962556,\n",
       " 35.3: 0.6760144132852889,\n",
       " 38.04: 0.7618674604417984,\n",
       " 37.955: 0.7592041359862133,\n",
       " 37.935: 0.7585774714084287,\n",
       " 36.68: 0.7192542691524362,\n",
       " 36.58: 0.7161209462635124,\n",
       " 36.21: 0.7045276515744947,\n",
       " 36.17: 0.7032743224189253,\n",
       " 35.535: 0.6833777220742596,\n",
       " 36.84: 0.7242675857747142,\n",
       " 36.42: 0.7111076296412345,\n",
       " 33.19: 0.6099013003289988,\n",
       " 32.45: 0.5867147109509635,\n",
       " 32.08: 0.5751214162619457,\n",
       " 32.39: 0.5848347172176093,\n",
       " 33.2927: 0.6131192229359236,\n",
       " 32.85: 0.5992480025066583,\n",
       " 32.15: 0.5773147422841923,\n",
       " 32.97: 0.6030079899733667,\n",
       " 33.72: 0.6265079116402945,\n",
       " 33.955: 0.6338712204292651,\n",
       " 33.87: 0.63120789597368,\n",
       " 33.58: 0.6221212595958012,\n",
       " 33.03: 0.604887983706721,\n",
       " 32.64: 0.5926680244399185,\n",
       " 32.49: 0.587968040106533,\n",
       " 32.46: 0.5870280432398559,\n",
       " 33.0: 0.6039479868400438,\n",
       " 32.35: 0.5835813880620399,\n",
       " 31.72: 0.5638414538618204,\n",
       " 31.16: 0.5462948456838478,\n",
       " 31.26: 0.5494281685727715,\n",
       " 31.96: 0.5713614287952373,\n",
       " 31.77: 0.5654081153062824,\n",
       " 31.82: 0.5669747767507441,\n",
       " 32.22: 0.5795080683064389,\n",
       " 32.4211: 0.5858091806360646,\n",
       " 32.42: 0.5857747140842864,\n",
       " 31.99: 0.5723014256619144,\n",
       " 31.54: 0.5582014726617578,\n",
       " 30.6315: 0.529735234215886,\n",
       " 30.63: 0.5296882343725522,\n",
       " 30.41: 0.5227949240169201,\n",
       " 30.24: 0.5174682751057497,\n",
       " 29.93: 0.5077549741500861,\n",
       " 29.86: 0.5055616481278395,\n",
       " 29.77: 0.5027416575278083,\n",
       " 30.12: 0.5137082876390413,\n",
       " 29.98: 0.5093216355945481,\n",
       " 29.92: 0.5074416418611938,\n",
       " 29.91: 0.5071283095723015,\n",
       " 29.48: 0.49365502114992954,\n",
       " 29.97: 0.5090083033056556,\n",
       " 30.78: 0.5343882187059377,\n",
       " 30.93: 0.5390882030393231,\n",
       " 30.4: 0.5224815917280276,\n",
       " 30.05: 0.5115149616167947,\n",
       " 29.575: 0.49663167789440704,\n",
       " 29.15: 0.48331505561648125,\n",
       " 28.88: 0.47485508381638725,\n",
       " 29.18: 0.4842550524831584,\n",
       " 29.01: 0.4789284035719882,\n",
       " 28.91: 0.4757950806830644,\n",
       " 28.73: 0.47015509948300177,\n",
       " 28.93: 0.4764217452608491,\n",
       " 28.92: 0.47610841297195683,\n",
       " 29.05: 0.4801817327275576,\n",
       " 28.63: 0.467021776594078,\n",
       " 29.4: 0.49114836283879054,\n",
       " 29.71: 0.5008616637944541,\n",
       " 29.61: 0.4977283409055303,\n",
       " 29.41: 0.49146169512768295,\n",
       " 28.84: 0.47360175466081783,\n",
       " 29.72: 0.5011749960833464,\n",
       " 29.82: 0.50430831897227,\n",
       " 29.75: 0.5021149929500235,\n",
       " 30.51: 0.5259282469058438,\n",
       " 37.76: 0.7530941563528121,\n",
       " 38.78: 0.785054049819834,\n",
       " 39.31: 0.8016606611311297,\n",
       " 38.27: 0.7690741030863231,\n",
       " 39.41: 0.8047939840200531,\n",
       " 39.595: 0.8105906313645621,\n",
       " 39.35: 0.8029139902866991,\n",
       " 39.47: 0.8066739777534074,\n",
       " 39.805: 0.8171706094313018,\n",
       " 39.26: 0.8000939996866676,\n",
       " 39.22: 0.7988406705310982,\n",
       " 39.67: 0.812940623531255,\n",
       " 40.06: 0.8251605827980574,\n",
       " 39.83: 0.8179539401535327,\n",
       " 38.61: 0.7797274009086635,\n",
       " 39.25: 0.7997806673977753,\n",
       " 40.0304: 0.824233119222936,\n",
       " 40.815: 0.8488171706094312,\n",
       " 40.61: 0.8423938586871377,\n",
       " 41.72: 0.8771737427541908,\n",
       " 41.18: 0.8602537991540028,\n",
       " 41.06: 0.8564938116872944,\n",
       " 42.85: 0.9125802913990287,\n",
       " 42.94: 0.9154002819990599,\n",
       " 42.68: 0.9072536424878583,\n",
       " 42.39: 0.8981670061099797,\n",
       " 42.88: 0.9135202882657059,\n",
       " 42.19: 0.8919003603321322,\n",
       " 42.33: 0.8962870123766253,\n",
       " 43.11: 0.9207269309102303,\n",
       " 43.05: 0.9188469371768759,\n",
       " 42.51: 0.901926993576688,\n",
       " 43.84: 0.9436001879993734,\n",
       " 44.56: 0.9661601127996241,\n",
       " 43.62: 0.936706877643741,\n",
       " 42.11: 0.8893937020209932,\n",
       " 41.64: 0.8746670844430519,\n",
       " 41.9: 0.8828137239542534,\n",
       " 41.82: 0.8803070656431146,\n",
       " 41.3: 0.8640137866207112,\n",
       " 41.53: 0.8712204292652358,\n",
       " 41.0: 0.8546138179539401,\n",
       " 40.81: 0.8486605044649852,\n",
       " 41.59: 0.8731004229985901,\n",
       " 42.36: 0.8972270092433025,\n",
       " 41.38: 0.8665204449318503,\n",
       " 41.05: 0.8561804793984019,\n",
       " 40.11: 0.8267272442425192,\n",
       " 39.775: 0.8162306125646247,\n",
       " 40.39: 0.8355005483315056,\n",
       " 40.38: 0.8351872160426133,\n",
       " 40.3941: 0.8356290145699514,\n",
       " 40.94: 0.8527338242205859,\n",
       " 40.33: 0.8336205545981512,\n",
       " 40.78: 0.847720507598308,\n",
       " 39.615: 0.8112172959423469,\n",
       " 41.7236: 0.8772865423781919,\n",
       " 41.01: 0.8549271502428324,\n",
       " 40.82: 0.8489738367538775,\n",
       " 40.9: 0.8514804950650163,\n",
       " 37.91: 0.7577941406861975,\n",
       " 36.82: 0.7236409211969294,\n",
       " 36.83: 0.7239542534858217,\n",
       " 37.56: 0.7468275105749648,\n",
       " 37.82: 0.7549741500861664,\n",
       " 37.9435: 0.7588438038539871,\n",
       " 37.17: 0.7346075513081624,\n",
       " 36.97: 0.7283409055303148,\n",
       " 36.88: 0.7255209149302836,\n",
       " 36.29: 0.7070343098856336,\n",
       " 35.87: 0.693874353752154,\n",
       " 35.6: 0.6854143819520602,\n",
       " 35.94: 0.6960676797744006,\n",
       " 35.885: 0.6943443521854926,\n",
       " 35.224000000000004: 0.6736330878897071,\n",
       " 34.28: 0.6440545198182673,\n",
       " 34.61: 0.6543944853517154,\n",
       " 34.92: 0.664107786307379,\n",
       " 34.57: 0.653141156196146,\n",
       " 34.82: 0.6609744634184552,\n",
       " 34.99: 0.6663011123296256,\n",
       " 35.33: 0.6769544101519661,\n",
       " 35.81: 0.6919943600188,\n",
       " 36.55: 0.7151809493968352,\n",
       " 36.11: 0.7013943286855711,\n",
       " 36.04: 0.6992010026633244,\n",
       " 35.76: 0.690427698574338,\n",
       " 37.05: 0.7308475638414538,\n",
       " 36.854: 0.7247062509791633,\n",
       " 37.62: 0.7487075043083189,\n",
       " 36.8: 0.7230142566191445,\n",
       " 35.96: 0.6966943443521855,\n",
       " 35.9543: 0.6965157449475169,\n",
       " 34.97: 0.6656744477518408,\n",
       " 34.04: 0.6365345448848503,\n",
       " 36.3: 0.707347642174526,\n",
       " 36.6: 0.7167476108412972,\n",
       " 36.5237: 0.7143568854770483,\n",
       " 37.23: 0.7364875450415164,\n",
       " 37.24: 0.7368008773304089,\n",
       " 37.33: 0.7396208679304401,\n",
       " 36.92: 0.7267742440858531,\n",
       " 37.47: 0.7440075199749333,\n",
       " 38.05: 0.7621807927306908,\n",
       " 36.6425: 0.7180792730690897,\n",
       " 36.37: 0.7095409681967726,\n",
       " 37.86: 0.7562274792417358,\n",
       " 37.8203: 0.7549835500548332,\n",
       " 38.33: 0.7709540968196772,\n",
       " 38.12: 0.7643741187529374,\n",
       " 39.45: 0.8060473131756228,\n",
       " 39.96: 0.8220272599091336,\n",
       " 38.84: 0.7869340435531882,\n",
       " 39.65: 0.8123139589534701,\n",
       " 38.63: 0.7803540654864485,\n",
       " 38.18: 0.7662541124862917,\n",
       " 38.19: 0.766567444775184,\n",
       " 38.8: 0.7856807143976186,\n",
       " 36.91: 0.7264609117969606,\n",
       " 33.82: 0.6296412345292182,\n",
       " 34.32: 0.6453078489738368,\n",
       " 34.2: 0.6415478615071284,\n",
       " 34.23: 0.6424878583738053,\n",
       " 34.34: 0.6459345135516216,\n",
       " 34.11: 0.6387278709070969,\n",
       " 34.5125: 0.6513394955350149,\n",
       " 34.8068: 0.6605608647971174,\n",
       " 34.51: 0.6512611624627918,\n",
       " 34.37: 0.6468745104182985,\n",
       " 33.9: 0.6321478928403571,\n",
       " 33.81: 0.6293279022403259,\n",
       " 33.23: 0.6111546294845682,\n",
       " 32.7: 0.5945480181732729,\n",
       " 31.73: 0.5641547861507129,\n",
       " 31.95: 0.571048096506345,\n",
       " 32.92: 0.601441328528905,\n",
       " 32.28: 0.5813880620397932,\n",
       " 32.34: 0.5832680557731476,\n",
       " 32.03: 0.573554754817484,\n",
       " 30.88: 0.5375215415948614,\n",
       " 30.71: 0.532194892683691,\n",
       " 30.94: 0.5394015353282157,\n",
       " 31.04: 0.5425348582171392,\n",
       " 30.885: 0.5376782077393076,\n",
       " 30.585: 0.5282782390725365,\n",
       " 30.39: 0.5221682594391351,\n",
       " 30.065: 0.5119849600501333,\n",
       " 30.28: 0.5187216042613191,\n",
       " 29.9: 0.506814977283409,\n",
       " 30.99: 0.5409681967726775,\n",
       " 31.88: 0.5688547704840984,\n",
       " 30.81: 0.5353282155726148,\n",
       " 30.6: 0.528748237505875,\n",
       " 31.21: 0.5478615071283096,\n",
       " 31.15: 0.5459815133949553,\n",
       " 30.97: 0.5403415321948927,\n",
       " 30.55: 0.5271815760614132,\n",
       " 30.23: 0.5171549428168574,\n",
       " 29.6598: 0.49928873570421434,\n",
       " 29.42: 0.49177502741657536,\n",
       " 30.31: 0.5196616011279963,\n",
       " 33.75: 0.6274479085069716,\n",
       " 33.92: 0.6327745574181419,\n",
       " 33.24: 0.6114679617734607,\n",
       " 32.96: 0.6026946576844744,\n",
       " 32.79: 0.597368008773304,\n",
       " 31.42: 0.5544414851950493,\n",
       " 31.46: 0.5556948143506188,\n",
       " 32.12: 0.5763747454175152,\n",
       " 31.98: 0.5719880933730221,\n",
       " 30.91: 0.5384615384615385,\n",
       " 30.72: 0.5325082249725833,\n",
       " 31.925: 0.5702647657841141,\n",
       " 32.77: 0.5967413441955194,\n",
       " 32.43: 0.5860880463731787,\n",
       " 32.26: 0.5807613974620084,\n",
       " 29.768: 0.5026789910700298,\n",
       " 28.31: 0.4569951433495221,\n",
       " 27.87: 0.44320852263825794,\n",
       " 28.34: 0.4579351402161993,\n",
       " 27.84: 0.44226852577158077,\n",
       " 27.26: 0.42409525301582335,\n",
       " 26.8: 0.4096819677267743,\n",
       " 26.26: 0.39276202412658634,\n",
       " 27.04: 0.4172019426601911,\n",
       " 28.51: 0.46326178912736965,\n",
       " 32.66: 0.5932946890177031,\n",
       " 33.08: 0.6064546451511827,\n",
       " 33.2: 0.6102146326178913,\n",
       " 35.05: 0.6681811060629796,\n",
       " 34.85: 0.6619144602851325,\n",
       " 33.88: 0.6315212282625725,\n",
       " 32.255: 0.5806047313175623,\n",
       " 32.675: 0.5937646874510417,\n",
       " 31.11: 0.5447281842393858,\n",
       " 32.5: 0.5882813723954253,\n",
       " 32.21: 0.5791947360175466,\n",
       " 30.11: 0.5133949553501488,\n",
       " 29.87: 0.5058749804167321,\n",
       " 32.36: 0.5838947203509322,\n",
       " 31.52: 0.5575748080839731,\n",
       " 31.1: 0.5444148519504936,\n",
       " 29.94: 0.5080683064389787,\n",
       " 31.84: 0.567601441328529,\n",
       " 32.6: 0.5914146952843491,\n",
       " 32.62: 0.5920413598621337,\n",
       " 32.75: 0.5961146796177346,\n",
       " 31.47: 0.5560081466395111,\n",
       " 31.78: 0.5657214475951747,\n",
       " 33.39: 0.6161679461068463,\n",
       " 34.38: 0.647187842707191,\n",
       " 33.84: 0.6302678991070031,\n",
       " 33.37: 0.6155412815290615,\n",
       " 33.85: 0.6305812313958954,\n",
       " 34.35: 0.6462478458405139,\n",
       " 31.3: 0.550681497728341,\n",
       " 31.62: 0.5607081309728968,\n",
       " 30.76: 0.5337615541281531,\n",
       " 27.305: 0.42550524831583897,\n",
       " 28.07: 0.4494751684161053,\n",
       " 28.68: 0.4685884380385399,\n",
       " 28.975: 0.47783174056086486,\n",
       " 28.96: 0.4773617421275263,\n",
       " 27.59: 0.43443521854927153,\n",
       " 26.19: 0.3905686981043397,\n",
       " 26.7614: 0.4084725050916497,\n",
       " 27.72: 0.4385085383048723,\n",
       " 27.97: 0.4463418455271816,\n",
       " 28.25: 0.45511514961616795,\n",
       " 27.91: 0.44446185179382736,\n",
       " 28.0: 0.4472818423938587,\n",
       " 28.41: 0.4601284662384459,\n",
       " 28.8: 0.47234842550524836,\n",
       " 28.44: 0.46106846310512306,\n",
       " 27.93: 0.4450885163716121,\n",
       " 28.49: 0.46263512454958483,\n",
       " 29.24: 0.4861350462165126,\n",
       " 28.82: 0.47297509008303307,\n",
       " 28.43: 0.46075513081623065,\n",
       " 29.25: 0.486448378505405,\n",
       " 30.35: 0.5209149302835657,\n",
       " 29.9531: 0.5084787717374275,\n",
       " 34.48: 0.6503211655961145,\n",
       " 34.59: 0.6537678207739308,\n",
       " 35.21: 0.6731944226852578,\n",
       " 34.89: 0.6631677894407019,\n",
       " 33.9279: 0.6330220899263669,\n",
       " 33.35: 0.6149146169512768,\n",
       " 32.2: 0.5788814037286543,\n",
       " 32.415: 0.5856180479398402,\n",
       " 31.951: 0.5710794297352342,\n",
       " 32.515: 0.5887513708287639,\n",
       " 32.02: 0.5732414225285917,\n",
       " 31.81: 0.5666614444618518,\n",
       " 32.55: 0.589848033839887,\n",
       " 31.45: 0.5553814820617266,\n",
       " 31.8: 0.5663481121729596,\n",
       " 31.07: 0.5434748550838163,\n",
       " 42.14: 0.8903336988876703,\n",
       " 42.35: 0.8969136769544102,\n",
       " 42.4: 0.898480338398872,\n",
       " 43.23: 0.9244869183769386,\n",
       " 42.74: 0.9091336362212127,\n",
       " 43.15: 0.9219802600657997,\n",
       " 43.91: 0.9457935140216198,\n",
       " 43.93: 0.9464201785994046,\n",
       " 44.36: 0.9598934670217766,\n",
       " 42.22: 0.8928403571988093,\n",
       " 43.63: 0.9370202099326336,\n",
       " 42.08: 0.8884537051543161,\n",
       " 44.61: 0.9677267742440858,\n",
       " 43.55: 0.9345135516214945,\n",
       " 43.8: 0.9423468588438038,\n",
       " 42.75: 0.909446968510105,\n",
       " 43.56: 0.934826883910387,\n",
       " 42.49: 0.9013003289989033,\n",
       " 43.68: 0.9385868713770954,\n",
       " 43.51: 0.933260222465925,\n",
       " 43.325: 0.9274635751214163,\n",
       " 44.5: 0.9642801190662698,\n",
       " 44.2: 0.9548801503994987,\n",
       " 45.4401: 0.9937364875450415,\n",
       " 43.57: 0.9351402161992793,\n",
       " 45.64: 1.0,\n",
       " 43.4199: 0.9304370985430048,\n",
       " 42.41: 0.8987936706877643,\n",
       " 40.66: 0.8439605201315994,\n",
       " 39.42: 0.8051073163089457,\n",
       " 38.64: 0.7806673977753408,\n",
       " 39.21: 0.7985273382422059,\n",
       " 39.19: 0.7979006736644211,\n",
       " 35.95: 0.6963810120632932,\n",
       " 35.09: 0.6694344352185494,\n",
       " 34.25: 0.6431145229515901,\n",
       " 34.08: 0.6377878740404198,\n",
       " 33.31: 0.6136612877957074,\n",
       " 32.83: 0.5986213379288735,\n",
       " 32.9: 0.60081466395112,\n",
       " 32.2108: 0.579219802600658,\n",
       " 32.281: 0.5814193952686824,\n",
       " 32.67: 0.5936080213065956,\n",
       " 32.93: 0.6017546608177973,\n",
       " 32.2501: 0.5804511984960051,\n",
       " 32.58: 0.5907880307065643,\n",
       " 31.94: 0.5707347642174527,\n",
       " 31.03: 0.5422215259282469,\n",
       " 29.85: 0.5052483158389472,\n",
       " 29.95: 0.508381638727871,\n",
       " 29.6: 0.497415008616638,\n",
       " 28.59: 0.46576844743850854,\n",
       " 28.14: 0.4516684944383519,\n",
       " 29.63: 0.49835500548331507,\n",
       " 30.85: 0.5365815447281842,\n",
       " 31.65: 0.5616481278395737,\n",
       " 30.96: 0.5400281999060003,\n",
       " 29.43: 0.49208835970546766,\n",
       " 28.36: 0.458561804793984,\n",
       " 28.78: 0.47172176092746365,\n",
       " 28.28: 0.4560551464828451,\n",
       " 28.1: 0.45041516528278247,\n",
       " 26.6: 0.40341532194892693,\n",
       " 27.22: 0.42284192386025377,\n",
       " 27.75: 0.43944853517154947,\n",
       " 27.88: 0.44352185492715024,\n",
       " 30.7: 0.5318815603947987,\n",
       " 30.7907: 0.5347234842550525,\n",
       " 31.175: 0.5467648441171864,\n",
       " 32.05: 0.5741814193952686,\n",
       " 30.61: 0.5290615697947673,\n",
       " 35.52: 0.6829077236409212,\n",
       " 35.4: 0.6791477361742126,\n",
       " 34.09: 0.6381012063293123,\n",
       " 34.83: 0.6612877957073475,\n",
       " 34.9367: 0.6646310512298292,\n",
       " 34.68: 0.656587811373962,\n",
       " 33.99: 0.6349678834403886,\n",
       " 31.49: 0.556634811217296,\n",
       " 31.97: 0.5716747610841296,\n",
       " 31.63: 0.5610214632617891,\n",
       " 32.6472: 0.592893623687921,\n",
       " 32.68: 0.593921353595488,\n",
       " 33.0599: 0.6058248472505091,\n",
       " 30.64: 0.5300015666614445,\n",
       " 30.8631: 0.5369920100266333,\n",
       " 29.68: 0.4999216669277769,\n",
       " 25.76: 0.3770954096819678,\n",
       " 24.2: 0.3282155726147579,\n",
       " 24.1: 0.3250822497258343,\n",
       " 25.7: 0.3752154159486135,\n",
       " 25.44: 0.3670687764374119,\n",
       " 25.14: 0.3576688077706408,\n",
       " 24.55: 0.339182202725991,\n",
       " 22.3: 0.2686824377252076,\n",
       " 22.04: 0.26053579821400596,\n",
       " 22.1: 0.26241579194736026,\n",
       " 22.41: 0.2721290929030237,\n",
       " 22.86: 0.2862290459031803,\n",
       " 23.72: 0.31317562274792415,\n",
       " 24.22: 0.3288422371925427,\n",
       " 24.51: 0.3379288735704215,\n",
       " 24.93: 0.351088829703901,\n",
       " 23.9: 0.3188156039479868,\n",
       " 23.76: 0.31442895190349374,\n",
       " 24.07: 0.32414225285915715,\n",
       " 23.88: 0.3181889393702021,\n",
       " 23.685: 0.31207895973680083,\n",
       " 23.85: 0.31724894250352503,\n",
       " 23.91: 0.3191289362368792,\n",
       " 24.17: 0.3272755757480809,\n",
       " 24.38: 0.3338555538148206,\n",
       " 24.7: 0.34388218705937645,\n",
       " 24.69: 0.34356885477048416,\n",
       " 23.13: 0.2946890177032743,\n",
       " 22.185: 0.2650791164029453,\n",
       " 21.62: 0.24737584208052646,\n",
       " 21.52: 0.2442425191916027,\n",
       " 21.625: 0.2475325082249726,\n",
       " 21.1: 0.2310825630581232,\n",
       " 20.95: 0.22638257872473758,\n",
       " 20.97: 0.2270092433025223,\n",
       " 20.4: 0.2091493028356572,\n",
       " 20.3: 0.20601597994673354,\n",
       " 20.225: 0.2036659877800408,\n",
       " 20.12: 0.2003759987466709,\n",
       " 20.51: 0.21259595801347336,\n",
       " 20.52: 0.21290929030236566,\n",
       " 21.56: 0.24549584834717214,\n",
       " 21.7: 0.24988250039166535,\n",
       " 22.17: 0.26460911796960684,\n",
       " 21.8: 0.2530158232805891,\n",
       " 21.15: 0.23264922450258496,\n",
       " 20.7: 0.2185492715024283,\n",
       " 20.25: 0.2044493185022717,\n",
       " 19.985: 0.19614601284662384,\n",
       " 19.73: 0.18815603947986842,\n",
       " 19.88: 0.19285602381325395,\n",
       " 19.93: 0.1944226852577158,\n",
       " 19.74: 0.18846937176876075,\n",
       " 19.36: 0.17656274479085068,\n",
       " 19.37: 0.17687607707974312,\n",
       " 19.51: 0.18126272912423633,\n",
       " 19.26: 0.17342942190192706,\n",
       " 19.52: 0.18157606141312863,\n",
       " 19.64: 0.1853360488798371,\n",
       " 20.46: 0.21102929656901148,\n",
       " 21.06: 0.22982923390255364,\n",
       " 20.15: 0.20131599561334793,\n",
       " 18.9: 0.16214945950180162,\n",
       " 17.03: 0.10355632147892846,\n",
       " 17.23: 0.10982296725677584,\n",
       " 17.34: 0.11326962243459189,\n",
       " 17.83: 0.128622904590318,\n",
       " 17.65: 0.12298292339025534,\n",
       " 17.97: 0.1330095566348112,\n",
       " 18.11: 0.1373962086793044,\n",
       " 18.23: 0.14115619614601288,\n",
       " 18.35: 0.14491618361272135,\n",
       " 17.73: 0.12548958170139435,\n",
       " 17.43: 0.11608961303462323,\n",
       " 17.39: 0.11483628387905377,\n",
       " 17.66: 0.12329625567914776,\n",
       " 17.74: 0.12580291399028667,\n",
       " 17.5: 0.11828293905686982,\n",
       " 17.12: 0.10637631207895978,\n",
       " 16.78: 0.0957230142566192,\n",
       " 16.75: 0.09478301738994205,\n",
       " 16.755: 0.0949396835343882,\n",
       " 16.57: 0.08914303618987938,\n",
       " 16.82: 0.09697634341218865,\n",
       " 17.42: 0.11577628074573092,\n",
       " 17.35: 0.11358295472348431,\n",
       " 17.51: 0.11859627134576224,\n",
       " 17.48: 0.1176562744790851,\n",
       " 17.47: 0.11734294219019267,\n",
       " 17.95: 0.13238289205702647,\n",
       " 17.94: 0.13206955976813417,\n",
       " 18.09: 0.13676954410151967,\n",
       " 17.7: 0.1245495848347172,\n",
       " 17.27: 0.11107629641234529,\n",
       " 17.08: 0.10512298292339022,\n",
       " 16.8301: 0.09729280902396999,\n",
       " 16.5162: 0.08745730847563847,\n",
       " 16.44: 0.0850697164342786,\n",
       " 16.58: 0.0894563684787717,\n",
       " 16.88: 0.09885633714554283,\n",
       " 16.8: 0.09634967883440392,\n",
       " 16.6: 0.09008303305655653,\n",
       " 16.61: 0.09039636534544884,\n",
       " 16.51: 0.0872630424565252,\n",
       " 16.14: 0.07566974776750747,\n",
       " 15.9301: 0.06909290302365659,\n",
       " 15.77: 0.06407645307848973,\n",
       " 15.86: 0.06689644367852107,\n",
       " 15.96: 0.07002976656744482,\n",
       " 15.93: 0.06908976970076766,\n",
       " 16.01: 0.07159642801190669,\n",
       " 15.67: 0.06094313018956605,\n",
       " 15.73: 0.06282312392292028,\n",
       " 16.05: 0.07284975716747615,\n",
       " 16.24: 0.0788030706564311,\n",
       " 16.1299: 0.07535328215572613,\n",
       " 15.945: 0.06955976813410625,\n",
       " 15.91: 0.06846310512298294,\n",
       " 16.0: 0.07128309572301426,\n",
       " 16.52: 0.08757637474541752,\n",
       " 16.5: 0.08694971016763278,\n",
       " 19.27: 0.17374275419081936,\n",
       " 19.69: 0.18690271032429898,\n",
       " 19.82: 0.19097603007989977,\n",
       " 20.18: 0.20225599248002507,\n",
       " 19.83: 0.19128936236879207,\n",
       " 19.41: 0.17812940623531257,\n",
       " 19.33: 0.17562274792417354,\n",
       " 19.08: 0.1677894407018643,\n",
       " 18.91: 0.16246279179069406,\n",
       " 18.1: 0.13708287639041208,\n",
       " 17.775: 0.12689957700140997,\n",
       " 17.63: 0.12235625881247061,\n",
       " 17.41: 0.1154629484568385,\n",
       " 17.75: 0.12611624627917908,\n",
       " 18.12: 0.13770954096819682,\n",
       " 18.15: 0.13864953783487385,\n",
       " 17.11: 0.10606297979006736,\n",
       " 16.84: 0.09760300798997337,\n",
       " 16.55: 0.08851637161209466,\n",
       " 16.46: 0.08569638101206334,\n",
       " 16.76: 0.09509634967883447,\n",
       " 16.27: 0.07974306752310825,\n",
       " 16.45: 0.08538304872317092,\n",
       " 17.3: 0.11201629327902243,\n",
       " 18.02: 0.13457621807927306,\n",
       " 18.22: 0.14084286385712044,\n",
       " 18.2: 0.14021619927933573,\n",
       " 18.08: 0.13645621181262726,\n",
       " 18.18: 0.139589534701551,\n",
       " 17.98: 0.13332288892370361,\n",
       " 18.27: 0.14240952530158232,\n",
       " 19.09: 0.1681027729907567,\n",
       " 18.63: 0.15368948770170765,\n",
       " 18.34: 0.14460285132382894,\n",
       " 18.31: 0.1436628544571518,\n",
       " 18.25: 0.14178286072379762,\n",
       " 18.195: 0.14005953313488959,\n",
       " 18.16: 0.13896287012376626,\n",
       " 18.37: 0.14554284819050609,\n",
       " 18.36: 0.14522951590161365,\n",
       " 16.97: 0.10167632774557415,\n",
       " 16.43: 0.0847563841453862,\n",
       " 15.8: 0.06501644994516688,\n",
       " 15.76: 0.06376312078959738,\n",
       " 14.63: 0.028356572144759555,\n",
       " 14.56: 0.026163246122512952,\n",
       " 14.41: 0.021463261789127386,\n",
       " 14.51: 0.02459658467805108,\n",
       " 14.44: 0.022403258655804476,\n",
       " 14.27: 0.017076609744634184,\n",
       " 14.12: 0.012376625411248615,\n",
       " 14.22: 0.015509948300172363,\n",
       " 14.26: 0.01676327745574182,\n",
       " 14.2: 0.014883283722387581,\n",
       " 14.25: 0.016449945166849455,\n",
       " 14.3: 0.01801660661131133,\n",
       " 14.58: 0.02678991070029768,\n",
       " 14.65: 0.02898323672254428,\n",
       " 14.91: 0.037129876233745904,\n",
       " 14.9: 0.03681654394485354,\n",
       " 14.7: 0.0305498981670061,\n",
       " 14.8: 0.03368322105592985,\n",
       " 14.75: 0.032116559611467976,\n",
       " 15.03: 0.040889863700454325,\n",
       " 14.73: 0.03148989503368325,\n",
       " 14.32: 0.018643271189096058,\n",
       " 14.5: 0.024283252389158714,\n",
       " 14.82: 0.03430988563371457,\n",
       " 15.04: 0.041203195989346686,\n",
       " 14.85: 0.03524988250039167,\n",
       " 15.15: 0.0446498511671628,\n",
       " 15.1: 0.04308318972270093,\n",
       " 14.94: 0.03806987310042299,\n",
       " 15.08: 0.0424565251449162,\n",
       " 15.16: 0.04496318345605516,\n",
       " 15.5: 0.05561648127839575,\n",
       " 15.68: 0.06125646247845841,\n",
       " 15.72: 0.06250979163402792,\n",
       " 15.585: 0.05827980573398093,\n",
       " 15.74: 0.06313645621181264,\n",
       " 15.85: 0.0665831113896287,\n",
       " 15.9: 0.06814977283409057,\n",
       " 16.3: 0.0806830643897854,\n",
       " 16.36: 0.08256305812313959,\n",
       " 16.32: 0.08130972896757013,\n",
       " 15.51: 0.055929813567288114,\n",
       " 16.26: 0.07942973523421595,\n",
       " 18.045: 0.13535954880150405,\n",
       " 17.99: 0.1336362212125959,\n",
       " 17.44: 0.11640294532351564,\n",
       " 17.1: 0.10574964750117505,\n",
       " 16.91: 0.09979633401221998,\n",
       " 16.41: 0.08412971956760146,\n",
       " 16.53: 0.08788970703430994,\n",
       " 16.79: 0.0960363465455115,\n",
       " 16.59: 0.08976970076766412,\n",
       " 16.33: 0.08162306125646245,\n",
       " 16.83: 0.09728967570108096,\n",
       " 16.86: 0.09822967256775811,\n",
       " 16.96: 0.10136299545668186,\n",
       " 17.17: 0.10794297352342165,\n",
       " 17.32: 0.11264295785680717,\n",
       " 17.19: 0.10856963810120639,\n",
       " 16.21: 0.07786307378975407,\n",
       " 16.22: 0.07817640607864638,\n",
       " 16.2914: 0.08041359862133793,\n",
       " 16.42: 0.08444305185649388,\n",
       " 16.16: 0.0762964123452922,\n",
       " 17.01: 0.10292965690114372,\n",
       " 17.87: 0.12987623374588755,\n",
       " 18.53: 0.150556164812784,\n",
       " 18.71: 0.15619614601284668,\n",
       " 18.89: 0.16183612721290933,\n",
       " 18.94: 0.1634027886573712,\n",
       " 19.3832: 0.17728967570108098,\n",
       " 18.1307: 0.13804480651731166,\n",
       " 17.86: 0.12956290145699514,\n",
       " 17.735: 0.1256462478458405,\n",
       " 18.13: 0.13802287325708912,\n",
       " 17.85: 0.12924956916810285,\n",
       " 18.03: 0.1348895503681655,\n",
       " 18.51: 0.1499295002349993,\n",
       " 18.59: 0.15243615854613818,\n",
       " 18.64: 0.15400281999060006,\n",
       " 18.5: 0.14961616794610685,\n",
       " 18.07: 0.13614287952373494,\n",
       " 17.91: 0.13112956290145703,\n",
       " 17.77: 0.12674291085696382,\n",
       " 17.26: 0.11076296412345299,\n",
       " 17.38: 0.11452295159016135,\n",
       " 17.261: 0.11079429735234216,\n",
       " 17.64: 0.12266959110136302,\n",
       " 17.07: 0.1048096506344979,\n",
       " 17.15: 0.10731630894563682,\n",
       " 17.49: 0.11796960676797741,\n",
       " 16.74: 0.09446968510104962,\n",
       " 16.28: 0.08005639981200068,\n",
       " 17.67: 0.12360958796804017,\n",
       " 17.81: 0.12799624001253326,\n",
       " 16.93: 0.10042299859000471,\n",
       " 19.645: 0.18549271502428324,\n",
       " 19.6: 0.18408271972426765,\n",
       " 23.34: 0.3012689957700141,\n",
       " 23.455: 0.3048723170922763,\n",
       " 22.82: 0.28497571674761085,\n",
       " 22.44: 0.27306908976970085,\n",
       " 22.9: 0.2874823750587498,\n",
       " 21.65: 0.2483158389472035,\n",
       " 21.11: 0.23139589534701552,\n",
       " 18.44: 0.14773617421275267,\n",
       " 18.28: 0.14272285759047476,\n",
       " 18.74: 0.1571361428795237,\n",
       " 18.06: 0.13582954723484253,\n",
       " 17.9: 0.1308162306125646,\n",
       " 17.52: 0.11890960363465455,\n",
       " 17.68: 0.12392292025693248,\n",
       " 17.92: 0.13144289519034943,\n",
       " 19.795: 0.1901926993576689,\n",
       " 19.4775: 0.18024439918533605,\n",
       " 19.35: 0.17624941250195839,\n",
       " 18.38: 0.14585618047939838,\n",
       " 18.32: 0.1439761867460442,\n",
       " 18.3: 0.14334952216825947,\n",
       " 18.65: 0.15431615227949239,\n",
       " 18.52: 0.1502428325238916,\n",
       " 18.76: 0.15776280745730853,\n",
       " 18.92: 0.16277612407958647,\n",
       " 19.9: 0.19348268839103866,\n",
       " 20.29: 0.20570264765784113,\n",
       " 19.01: 0.1655961146796178,\n",
       " 19.1138: 0.1688485038383206,\n",
       " 18.56: 0.15149616167946103,\n",
       " 17.971: 0.13304088986370047,\n",
       " 17.935: 0.13191289362368788,\n",
       " 18.14: 0.13833620554598156,\n",
       " 17.36: 0.11389628701237663,\n",
       " 16.2: 0.07754974150086165,\n",
       " 16.4: 0.08381638727870903,\n",
       " 15.88: 0.06752310825630585,\n",
       " 15.69: 0.06156979476735077,\n",
       " 18.164: 0.13908820303932326,\n",
       " 18.17: 0.1392762024126587,\n",
       " 17.76: 0.1264295785680715,\n",
       " 18.45: 0.148049506501645,\n",
       " 18.05: 0.13551621494595023,\n",
       " 17.910999999999998: 0.13116089613034618,\n",
       " 17.24: 0.11013629954566814,\n",
       " 16.81: 0.09666301112329623,\n",
       " 16.9: 0.09948300172332755,\n",
       " 16.73: 0.09415635281215733,\n",
       " 15.46: 0.054363152122826296,\n",
       " 16.045: 0.07269309102303,\n",
       " 16.17: 0.07660974463418461,\n",
       " 16.15: 0.07598308005639978,\n",
       " 15.4: 0.05248315838947206,\n",
       " 15.71: 0.062196459345135555,\n",
       " 14.505: 0.024439918533604926,\n",
       " 14.0: 0.008616637944540196,\n",
       " 14.59: 0.027103242989190042,\n",
       " 14.81: 0.03399655334482221,\n",
       " 15.18: 0.04558984803383989,\n",
       " 14.96: 0.03869653767820778,\n",
       " 14.8463: 0.03513394955350148,\n",
       " 14.62: 0.028043239855867135,\n",
       " 14.23: 0.01582328058906473,\n",
       " 14.19: 0.014569951433495218,\n",
       " 14.06: 0.010496631677894434,\n",
       " 13.725: 0.0,\n",
       " 14.3301: 0.018959736800877338,\n",
       " 14.16: 0.013629954566818127,\n",
       " 14.04: 0.009869967100109652,\n",
       " 14.05: 0.01018329938900207,\n",
       " 14.13: 0.012689957700141035,\n",
       " 14.15: 0.013316622277925762,\n",
       " 13.98: 0.007989973366755469,\n",
       " 14.08: 0.011123296255679161,\n",
       " 13.92: 0.006109979633401231,\n",
       " 13.9: 0.0054833150556165035,\n",
       " 14.17: 0.01394328685571049,\n",
       " 17.02: 0.10324298919003604,\n",
       " 16.68: 0.09258969136769545,\n",
       " 17.06: 0.1044963183456055,\n",
       " 17.31: 0.11232962556791475,\n",
       " 17.14: 0.1070029766567445,\n",
       " 16.85: 0.0979163402788658,\n",
       " 16.89: 0.09916966943443525,\n",
       " 15.83: 0.06595644681184397,\n",
       " 15.33: 0.05028983236722546,\n",
       " 15.565: 0.057653141156196144,\n",
       " 16.7: 0.09321635594548017,\n",
       " 16.62: 0.09070969763434127,\n",
       " 16.13: 0.07535641547861505,\n",
       " 16.38: 0.08318972270092431,\n",
       " 18.33: 0.1442895190349365,\n",
       " 18.77: 0.15807613974620086,\n",
       " 19.06: 0.16716277612407957,\n",
       " 18.48: 0.14898950336832215,\n",
       " 17.715: 0.1250195832680558,\n",
       " 17.59: 0.12110292965690116,\n",
       " 17.78: 0.12705624314585623,\n",
       " 17.4975: 0.11820460598464669,\n",
       " 14.53: 0.025223249255835807,\n",
       " 13.91: 0.005796647344508867,\n",
       " 14.52: 0.024909916966943443,\n",
       " 14.31: 0.018329938900203693,\n",
       " 15.62: 0.059376468745104174,\n",
       " 16.29: 0.08036973210089299,\n",
       " 15.55: 0.05718314272285763,\n",
       " 16.77: 0.09540968196772677,\n",
       " 15.48: 0.054989816700611024,\n",
       " 17.61: 0.12172959423468588,\n",
       " 18.47: 0.1486761710794297,\n",
       " 19.32: 0.17530941563528124,\n",
       " 20.198: 0.20281999060003136,\n",
       " 21.18: 0.2335892213692621,\n",
       " 21.85: 0.25458248472505096,\n",
       " 22.11: 0.26272912423625255,\n",
       " 22.15: 0.263982453391822,\n",
       " 22.21: 0.2658624471251763,\n",
       " 22.31: 0.2689957700140999,\n",
       " 22.5: 0.274949083503055,\n",
       " 22.55: 0.2765157449475169,\n",
       " 22.37: 0.2708757637474542,\n",
       " 22.09: 0.26210245965846785,\n",
       " 21.99: 0.2589691367695441,\n",
       " 22.66: 0.27996240012533297,\n",
       " 23.29: 0.29970233432555227,\n",
       " 23.8: 0.31568228105906315,\n",
       " 24.8: 0.3470155099483002,\n",
       " 24.34: 0.33260222465925116,\n",
       " 24.19: 0.3279022403258656,\n",
       " 23.54: 0.3075356415478615,\n",
       " 25.01: 0.35359548801504004,\n",
       " 24.91: 0.3504621651261163,\n",
       " 25.17: 0.3586088046373179,\n",
       " 25.0: 0.3532821557261476,\n",
       " 25.06: 0.3551621494595018,\n",
       " 25.67: 0.37427541908193646,\n",
       " 25.59: 0.37176876077079746,\n",
       " 25.02: 0.35390882030393234,\n",
       " 26.03: 0.3855553814820618,\n",
       " 25.93: 0.38242205859313805,\n",
       " 25.16: 0.3582954723484255,\n",
       " 24.9: 0.35014883283722387,\n",
       " 25.85: 0.3799154002819991,\n",
       " 26.37: 0.39620867930440234,\n",
       " 26.25: 0.3924486918376939,\n",
       " 26.68: 0.4059219802600658,\n",
       " 28.05: 0.4488485038383206,\n",
       " 28.45: 0.46138179539401536,\n",
       " 29.23: 0.4858217139276203,\n",
       " 29.04: 0.4798684004386652,\n",
       " 28.35: 0.4582484725050917,\n",
       " 27.76: 0.4397618674604419,\n",
       " 30.65: 0.5303148989503368,\n",
       " 30.48: 0.5249882500391666,\n",
       " 28.65: 0.4676484411718627,\n",
       " 30.57: 0.5278082406391978,\n",
       " 29.36: 0.48989503368322107,\n",
       " 28.38: 0.45918846937176877,\n",
       " 28.6: 0.466081779727401,\n",
       " 29.03: 0.4795550681497729,\n",
       " 28.01: 0.4475951746827511,\n",
       " 26.33: 0.3949553501488328,\n",
       " 24.65: 0.3423155256149146,\n",
       " 25.88: 0.38085539714867617,\n",
       " 24.915: 0.3506188312705624,\n",
       " 25.3979: 0.365749647501175,\n",
       " 26.575: 0.4026319912266959,\n",
       " 26.62: 0.40404198652671164,\n",
       " 27.1899: 0.42189879367068783,\n",
       " 26.99: 0.41563528121572924,\n",
       " 27.03: 0.4168886103712988,\n",
       " 27.0: 0.4159486135046217,\n",
       " 26.795: 0.40952530158232814,\n",
       " 27.17: 0.421275262415792,\n",
       " 26.95: 0.4143819520601598,\n",
       " 26.42: 0.3977753407488642}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalization(fname, attr, normType):\n",
    "    '''\n",
    "    Input Parameters:\n",
    "        fname: Name of the csv file containing historical quotes\n",
    "        attr: The attribute to be normalized (column name or position)\n",
    "        normType: The type of normalization \n",
    "    Output:\n",
    "        a dictionary where each key is the original column value and each value is the normalized column value. \n",
    "    '''\n",
    "    result = {}\n",
    "    \n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(fname)\n",
    "    \n",
    "    # Get the column we want to normalize\n",
    "    # If attr is an integer, use iloc to get the column by position\n",
    "    if isinstance(attr, int):\n",
    "        df_col = df.iloc[:, attr]\n",
    "    else:\n",
    "        df_col = df[attr]\n",
    "    \n",
    "    if normType == \"z_score\":\n",
    "        df_col_mean = df_col.mean()\n",
    "        df_col_std = df_col.std()\n",
    "        for index, value in df_col.items():\n",
    "            result[value] = (value - df_col_mean) / df_col_std\n",
    "    else:  # min_max normalization\n",
    "        df_col_min = df_col.min()\n",
    "        df_col_max = df_col.max()\n",
    "        for index, value in df_col.items():\n",
    "            result[value] = (value - df_col_min) / (df_col_max - df_col_min)\n",
    "            \n",
    "    return result\n",
    "\n",
    "normalization(\"./data/HistoricalQuotes.csv\", \"Low\", \"min_max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e0d7d290878957d9535e285ed9ba393",
     "grade": true,
     "grade_id": "test_normalization",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis cell has hidden test cases that will run after you submit your assignment. \\nYou can troubleshoot using the unit tests we shared below.\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This cell has hidden test cases that will run after you submit your assignment. \n",
    "You can troubleshoot using the unit tests we shared below.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T01:24:55.210777Z",
     "start_time": "2020-09-10T01:24:55.201476Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "862c679b0e1c220375a75868ae05a503",
     "grade": false,
     "grade_id": "correlation",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.864439715650828"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def correlation (fname1, attr1, fname2, attr2):\n",
    "    '''\n",
    "    Input Parameters:\n",
    "        fname1: name of the first csv file containing historical quotes\n",
    "        attr1: The attribute to consider in the first csv file (fname1)\n",
    "        fname2: name of the second csv file containing historical quotes\n",
    "        attr2: The attribute to consider in the second csv file (fname2)\n",
    "        \n",
    "    Output:\n",
    "        correlation coefficient between attr1 in fname1 and attr2 in fname2\n",
    "    '''\n",
    "    \n",
    "    correlation_coefficient = 0.0\n",
    "        \n",
    "    \n",
    "    #TODO: Write code given the Input / Output Paramters.\n",
    "    \n",
    "    # your code here\n",
    "    df1 = pd.read_csv(fname1)\n",
    "    df2 = pd.read_csv(fname2)\n",
    "    \n",
    "    # Convert column indices to names if integers are provided\n",
    "    if isinstance(attr1, int):\n",
    "        attr1 = df1.columns[attr1]\n",
    "    if isinstance(attr2, int):\n",
    "        attr2 = df2.columns[attr2]\n",
    "    \n",
    "    # Proceed with correlation calculation\n",
    "    column1 = pd.to_numeric(df1[attr1], errors='coerce').dropna()\n",
    "    column2 = pd.to_numeric(df2[attr2], errors='coerce').dropna()\n",
    "\n",
    "    correlation_coefficient = column1.corr(column2)\n",
    "\n",
    "    return correlation_coefficient\n",
    "correlation(\"./data/test1.csv\", 'High', \"./data/test2.csv\", 'Low')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f543a7eb3374de561e6640f3101fb49",
     "grade": true,
     "grade_id": "test_correlation",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis cell has hidden test cases that will run after you submit your assignment. \\nYou can troubleshoot using the unit tests we shared below.\\n'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This cell has hidden test cases that will run after you submit your assignment. \n",
    "You can troubleshoot using the unit tests we shared below.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T01:28:36.101216Z",
     "start_time": "2020-09-10T01:28:36.049564Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e26989a1a0f566bbde748e091e86193c",
     "grade": false,
     "grade_id": "cell-073dcfbad9049939",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.050s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=3 errors=0 failures=0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestKnn(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.loc1 = \"data/test1.csv\"\n",
    "        self.loc2 = \"data/test2.csv\"\n",
    "        file = open('data/testing_normalization', 'rb')\n",
    "        self.data_normalization = pickle.load(file)\n",
    "        file.close()\n",
    "        file = open('data/testing_correlation', 'rb')\n",
    "        self.data_correlation = pickle.load(file)\n",
    "        file.close()\n",
    "        file = open('data/testing_zscore', 'rb')\n",
    "        self.zscore = pickle.load(file)\n",
    "        \n",
    "    def test0(self):\n",
    "        \"\"\"\n",
    "        Test min_max normalization \n",
    "        \"\"\"\n",
    "        result = normalization(\"./data/normalization_test_data.csv\", 0, \"min_max\")\n",
    "        for key,value in self.data_normalization.items():\n",
    "            self.assertAlmostEqual(result[key],value, places = 1)\n",
    "            \n",
    "    \n",
    "    def test1(self):\n",
    "        \"\"\"\n",
    "        Test zcore normalization\n",
    "        \"\"\"\n",
    "        result = normalization(\"./data/normalization_test_data.csv\", 1, \"z_score\")\n",
    "        for key, value in self.zscore.items():\n",
    "            self.assertAlmostEqual(result[key], value, places = 1)\n",
    "    \n",
    "    def test2(self):\n",
    "        \"\"\"\n",
    "        Test correlation \n",
    "        \"\"\"\n",
    "        result = correlation('./data/correlation_test_data.csv', 0, \"./data/correlation_test_data.csv\", 0)\n",
    "        self.assertAlmostEqual(result,self.data_correlation, places = 1)\n",
    "       \n",
    "   \n",
    "tests = TestKnn()\n",
    "tests_to_run = unittest.TestLoader().loadTestsFromModule(tests)\n",
    "unittest.TextTestRunner().run(tests_to_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "288051f75f190c1b29700f8c866f0c4a",
     "grade": false,
     "grade_id": "cell-1d57af814dafe68f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Problem 2\n",
    "***\n",
    "\n",
    "There are 4 functions that need to be completed:\n",
    "\n",
    "1. For each of the graphs, the input function parameters and the expected output has been mentioned below.\n",
    "2. Use the dataset provided in \"./data/HistoricalQuotes.csv\" to plot the below graphs.\n",
    "3. Instructions have been provided within each function regarding which attributes to choose from.\n",
    "4. The dataset has the following attributes\n",
    "    - Date\n",
    "    - Close\n",
    "    - Volume\n",
    "    - Open\n",
    "    - High\n",
    "    - Low\n",
    "\n",
    "Note:\n",
    "- Make sure the dataset you are using is the one mentioned in the problem statement.\n",
    "- After defining your functions. Create another block to call these functions by passing the attributes mentioned in canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aff2da14c79cd0b36f2d98169672690e",
     "grade": false,
     "grade_id": "cell-09f7dfae43c9f6f8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# Plot size to 14\" x 7\"\n",
    "matplotlib.rc('figure', figsize = (14, 7))\n",
    "# Font size to 14\n",
    "matplotlib.rc('font', size = 14)\n",
    "# Do not display top and right frame lines\n",
    "matplotlib.rc('axes.spines', top = False, right = False)\n",
    "# Remove grid lines\n",
    "matplotlib.rc('axes', grid = False)\n",
    "# Set backgound color to white\n",
    "matplotlib.rc('axes', facecolor = 'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e320e21e3a51c6fc38e1065a5fce7b8",
     "grade": false,
     "grade_id": "cell-f262493a60cd8007",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def temporal_graph():\n",
    "    '''Input : x_data and y_data are the lists containing the data points for x and y axis\n",
    "    xlabel and ylabel are the labels that should be given to the corresponding axes\n",
    "    title contains the title of the graph\n",
    "    \n",
    "    Output : \n",
    "    Plot the temporal change of attributes High and Low values\n",
    "    Return a temporal graph with attributes Date on x-axis and a tuple of High and Low on y-axis displayed\n",
    "    \n",
    "    x_data - a python list of Dates using \"Date\" attribute from the dataset\n",
    "    y_data - a tuple of the High and Low values respectively. 'High' and 'Low' should be stored as python lists.\n",
    "             Ex: y_data = (list(df['attr_1']), list(df['attr_2']))\n",
    "    xlabel, ylabel - A string value representing the axes labels\n",
    "    title - A string representing the title for the graph\n",
    "    '''\n",
    "    \n",
    "    df = pd.read_csv('./data/HistoricalQuotes.csv')\n",
    "    \n",
    "    # your code here\n",
    "    \n",
    "    # your code here\n",
    "    x_data = list(df[\"Date\"])\n",
    "    y_data = (list(df['High']) , list(df['Low']))\n",
    "    xlabel = \"Date\"\n",
    "    ylabel = \"High - Low\"\n",
    "    title = \"temporal_graph\"\n",
    "    \n",
    "    return x_data,y_data,xlabel,ylabel,title\n",
    "    \n",
    "    \n",
    "    return x_data,y_data,xlabel,ylabel,title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10b78e6a952ddec151b6ef22c38ec8db",
     "grade": true,
     "grade_id": "cell-a8a9dace8000b375",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis cell has hidden test cases that will run after you submit your assignment. \\nYou can troubleshoot by calling the function and checking return types.\\n'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This cell has hidden test cases that will run after you submit your assignment. \n",
    "You can troubleshoot by calling the function and checking return types.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef467c73f896a2883c3e1bc51d35c11f",
     "grade": false,
     "grade_id": "cell-51ff89ef927d6018",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def boxplot():\n",
    "    '''Input : x_data and y_data are the lists containing the data points for x and y axis\n",
    "    base_color and median_color can be used to set colors in the graph.\n",
    "    xlabel and ylabel are the labels that should be given to the corresponding axes\n",
    "    title contains the title of the graph.\n",
    "    \n",
    "    Output : A boxplot with Open and Close attributes on the x-axis displayed\n",
    "    \n",
    "    x_data - a tuple of Open and Close values respectively. Open and Close should be stored as a python list.\n",
    "             Ex: x_data = (list(df['attr_1']), list(df['attr_2']))\n",
    "    xlabel, ylabel - A string value representing the axes labels\n",
    "    title - A string representing the title for the graph\n",
    "    '''\n",
    "    \n",
    "    df = pd.read_csv('./data/HistoricalQuotes.csv')\n",
    "        \n",
    "    # your code here    \n",
    "    x_data = (list(df['Open']) , list(df['Close']))\n",
    "    xlabel = \"Close\"\n",
    "    ylabel = \"Open\"\n",
    "    title = \"temporal_graph\"\n",
    "    \n",
    "        \n",
    "    \n",
    "    return x_data,xlabel,ylabel,title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fdca2d2c76a46b748804df557feadf39",
     "grade": true,
     "grade_id": "cell-34f53d2a937e45f2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis cell has hidden test cases that will run after you submit your assignment. \\nYou can troubleshoot by calling the function and checking return types.\\n'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This cell has hidden test cases that will run after you submit your assignment. \n",
    "You can troubleshoot by calling the function and checking return types.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6ab525c41e6e239d86036fcebe088341",
     "grade": false,
     "grade_id": "cell-6e477222af744e1e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def histogram():\n",
    "    '''Input : data is the list containing the data points for histogram buckets\n",
    "    xlabel and ylabel are the labels that should be given to the corresponding axes\n",
    "    title contains the title of the graph\n",
    "    \n",
    "    Output : A histogram of the Volume attribute displayed\n",
    "    \n",
    "    data - A python list containing the data associated with the Volume attribute\n",
    "    x_label, y_label - A string representing the axes labels \n",
    "    '''\n",
    "\n",
    "    df = pd.read_csv('./data/HistoricalQuotes.csv')\n",
    "\n",
    "    data = []\n",
    "    \n",
    "\n",
    "    # your code here\n",
    "    data = list(df.loc[:,\"Volume\"])\n",
    "    x_label = \"Volume\"\n",
    "    y_label = \"Volume\"\n",
    "        \n",
    "    return data, x_label, y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a4c6c8e00948adc5769275f48e7bd2d3",
     "grade": true,
     "grade_id": "cell-9719ed64b0c27717",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis cell has hidden test cases that will run after you submit your assignment. \\nYou can troubleshoot by calling the function and checking return types.\\n'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This cell has hidden test cases that will run after you submit your assignment. \n",
    "You can troubleshoot by calling the function and checking return types.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def amzn_new_plot(data_df):\n",
    "    '''Define this function as you would seem fit to display the plot that interests you using\n",
    "    the same dataset. Define your function parameters and display the resulting plots'''   \n",
    "    \n",
    "    # your code here\n",
    "    import matplotlib.pyplot as plt\n",
    "#     df = pd.read_csv('./data/HistoricalQuotes.csv')\n",
    "    \n",
    "#     data = list(df.loc[:,data_df])\n",
    "#     plt.hist(data)\n",
    "#     plt.show()\n",
    "\n",
    "    df = pd.read_csv('./data/HistoricalQuotes.csv')\n",
    "    \n",
    "    data = list(df.loc[:,data_df])\n",
    "    plt.hist(data)\n",
    "    plt.show()\n",
    "\n",
    "amzn_new_plot(\"Open\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
